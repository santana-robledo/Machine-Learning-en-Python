{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Módelos de clasificación con Keras",
   "id": "5d30b0f86ebe56fd"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Introducción\n",
    "\n",
    "En este laboratorio, aprenderemos cómo usar la biblioteca Keras para construir modelos para problemas de clasificación. Esta vez utilizaremos el popular conjunto de datos MNIST, un conjunto de imágenes.\n",
    "\n",
    "La base de datos MNIST (abreviatura de Modified National Institute of Standards and Technology database) es una gran base de datos de dígitos escritos a mano, comúnmente utilizada para entrenar diversos sistemas de procesamiento de imágenes. La base de datos también se usa ampliamente para entrenamiento y pruebas en el campo del aprendizaje automático.\n",
    "\n",
    "La base de datos MNIST contiene 60,000 imágenes de entrenamiento y 10,000 imágenes de prueba de dígitos escritos por estudiantes de secundaria y empleados de la Oficina del Censo de Estados Unidos.\n",
    "\n",
    "Además, de esta manera podrás comparar cómo se desempeñan las redes neuronales convencionales frente a las redes neuronales convolucionales, que construiremos en el siguiente módulo."
   ],
   "id": "167d338bf9e84c2f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Objetivos de este cuaderno\n",
    "* Usar la base de datos MNIST para entrenar diversos sistemas de procesamiento de imágenes\n",
    "* Construir una red neuronal\n",
    "* Entrenar y probar la red\n"
   ],
   "id": "b0c3bdfb07059de0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-19T02:16:20.430844100Z",
     "start_time": "2025-12-19T02:16:20.423458500Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import keras\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Input\n",
    "from keras.utils import to_categorical"
   ],
   "id": "fb53e3c6f235659e",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "La biblioteca Keras incluye de manera conveniente el conjunto de datos MNIST como parte de su API. Puedes consultar otros conjuntos de datos dentro de la biblioteca Keras [aquí](https://keras.io/datasets/)\n",
    ".\n",
    "\n",
    "Así que, vamos a cargar el conjunto de datos MNIST desde la biblioteca Keras. El conjunto de datos ya está dividido en un conjunto de entrenamiento y un conjunto de prueba."
   ],
   "id": "aefd0f8d56fba868"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-19T02:17:29.222367700Z",
     "start_time": "2025-12-19T02:17:25.010879400Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# import the data\n",
    "from keras.datasets import mnist\n",
    "\n",
    "# read the data\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
   ],
   "id": "9601c5214a34c027",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "\u001B[1m11490434/11490434\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 0us/step\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Verifiquemos el número de imágenes en cada conjunto. Según la documentación del conjunto de datos, deberíamos tener 60,000 imágenes en X_train y 10,000 imágenes en X_test",
   "id": "5c519f8ed26417b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-19T02:18:07.326326700Z",
     "start_time": "2025-12-19T02:18:07.284392900Z"
    }
   },
   "cell_type": "code",
   "source": "X_train.shape",
   "id": "427a56d44ef74fa2",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "El primer número en la tupla de salida es la cantidad de imágenes, y los otros dos números representan el tamaño de las imágenes en el conjunto de datos. Por lo tanto, cada imagen tiene 28 píxeles por 28 píxeles.",
   "id": "648773f61d9a1898"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Vamos a visualizar la primera imagen del conjunto de entrenamiento usando la capa de scripting de Matplotlib.",
   "id": "92270c2d7f3a5f39"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "plt.imshow(X_train[0])",
   "id": "614572206899ed0c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Con las redes neuronales convencionales, no podemos alimentar la imagen como entrada tal cual. Por lo tanto, necesitamos aplanar las imágenes en vectores unidimensionales, cada uno de tamaño 1 x (28 x 28) = 1 x 784.",
   "id": "4d4a32ed766bee90"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-19T02:19:18.976966100Z",
     "start_time": "2025-12-19T02:19:18.896113800Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# flatten images into one-dimensional vector\n",
    "\n",
    "num_pixels = X_train.shape[1] * X_train.shape[2] # find size of one-dimensional vector\n",
    "\n",
    "X_train = X_train.reshape(X_train.shape[0], num_pixels).astype('float32') # flatten training images\n",
    "X_test = X_test.reshape(X_test.shape[0], num_pixels).astype('float32') # flatten test images"
   ],
   "id": "63eb47df180143f5",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Dado que los valores de los píxeles pueden variar de 0 a 255, vamos a normalizar los vectores para que estén entre 0 y 1.",
   "id": "fbeda6f237755c3d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# normalize inputs from 0-255 to 0-1\n",
    "X_train = X_train / 255\n",
    "X_test = X_test / 255"
   ],
   "id": "fb172e0bb66ad7b9"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Finalmente, antes de empezar a construir nuestro modelo, recuerda que para clasificación necesitamos dividir nuestra variable objetivo en categorías. Para ello usamos la función to_categorical del paquete Keras Utilities.",
   "id": "a04e5d798be03bd4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-19T02:20:12.950203500Z",
     "start_time": "2025-12-19T02:20:12.892524600Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# one hot encode outputs\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)\n",
    "\n",
    "num_classes = y_test.shape[1]\n",
    "print(num_classes)"
   ],
   "id": "6020760a778b971c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Construye una red Neuronal",
   "id": "87776e6f9429d88e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-19T02:20:39.218082Z",
     "start_time": "2025-12-19T02:20:39.202416300Z"
    }
   },
   "cell_type": "code",
   "source": [
    "## Build a Neural Network\n",
    "\n",
    "# define classification model\n",
    "def classification_model():\n",
    "    # create model\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=(num_pixels,)))\n",
    "    model.add(Dense(num_pixels, activation='relu'))\n",
    "    model.add(Dense(100, activation='relu'))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    # compile model\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ],
   "id": "4e6ab37383b186c1",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Entrena y prueba la red",
   "id": "8f81d0e5b66a8586"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-19T02:22:03.625357400Z",
     "start_time": "2025-12-19T02:21:04.654285300Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# build the model\n",
    "model = classification_model()\n",
    "\n",
    "# fit the model\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, verbose=2)\n",
    "\n",
    "# evaluate the model\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)"
   ],
   "id": "10823bd729fd17f7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1875/1875 - 6s - 3ms/step - accuracy: 0.7656 - loss: 1.4059 - val_accuracy: 0.8754 - val_loss: 0.5504\n",
      "Epoch 2/10\n",
      "1875/1875 - 7s - 4ms/step - accuracy: 0.9122 - loss: 0.3489 - val_accuracy: 0.9391 - val_loss: 0.2371\n",
      "Epoch 3/10\n",
      "1875/1875 - 6s - 3ms/step - accuracy: 0.9438 - loss: 0.2081 - val_accuracy: 0.9480 - val_loss: 0.2015\n",
      "Epoch 4/10\n",
      "1875/1875 - 5s - 3ms/step - accuracy: 0.9549 - loss: 0.1722 - val_accuracy: 0.9448 - val_loss: 0.2060\n",
      "Epoch 5/10\n",
      "1875/1875 - 5s - 3ms/step - accuracy: 0.9634 - loss: 0.1379 - val_accuracy: 0.9622 - val_loss: 0.1698\n",
      "Epoch 6/10\n",
      "1875/1875 - 5s - 3ms/step - accuracy: 0.9683 - loss: 0.1223 - val_accuracy: 0.9649 - val_loss: 0.1549\n",
      "Epoch 7/10\n",
      "1875/1875 - 6s - 3ms/step - accuracy: 0.9731 - loss: 0.1033 - val_accuracy: 0.9629 - val_loss: 0.1747\n",
      "Epoch 8/10\n",
      "1875/1875 - 6s - 3ms/step - accuracy: 0.9735 - loss: 0.1059 - val_accuracy: 0.9610 - val_loss: 0.1728\n",
      "Epoch 9/10\n",
      "1875/1875 - 5s - 3ms/step - accuracy: 0.9776 - loss: 0.0904 - val_accuracy: 0.9675 - val_loss: 0.1584\n",
      "Epoch 10/10\n",
      "1875/1875 - 6s - 3ms/step - accuracy: 0.9784 - loss: 0.0894 - val_accuracy: 0.9693 - val_loss: 0.1588\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Vamos a imprimir la exactitud (accuracy) y el error correspondiente.",
   "id": "53ac4ec9617f4b42"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-19T02:22:03.932197300Z",
     "start_time": "2025-12-19T02:22:03.914380Z"
    }
   },
   "cell_type": "code",
   "source": "print('Accuracy: {}% \\n Error: {}'.format(scores[1], 1 - scores[1]))",
   "id": "cb47d52ad2d2d0e9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9692999720573425% \n",
      " Error: 0.03070002794265747\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Ejecutar solo 10 épocas podría tomar más de 20 minutos. Pero disfruta los resultados a medida que se van generando.",
   "id": "adadf7f962e2219e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "A veces, no es posible volver a entrenar tu modelo cada vez que quieres usarlo, especialmente si tienes recursos computacionales limitados y entrenar tu modelo puede tomar mucho tiempo. Por lo tanto, con la biblioteca Keras, puedes guardar tu modelo después del entrenamiento. Para hacer esto, usamos el método save",
   "id": "21f882183da5ff52"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-19T02:22:46.156686300Z",
     "start_time": "2025-12-19T02:22:46.066150600Z"
    }
   },
   "cell_type": "code",
   "source": "model.save('classification_model.keras')",
   "id": "ecc8cfcba66c07cc",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Dado que nuestro modelo contiene arreglos multidimensionales de datos, los modelos generalmente se guardan como archivos .keras.",
   "id": "7b85bd71f04b1b70"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Cuando estés listo para usar tu modelo nuevamente, utiliza la función load_model de keras.saving.",
   "id": "85c12815d4fa40aa"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-19T02:23:44.238586600Z",
     "start_time": "2025-12-19T02:23:44.144777100Z"
    }
   },
   "cell_type": "code",
   "source": "pretrained_model = keras.saving.load_model('classification_model.keras')",
   "id": "4263e604457d7cc2",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Practice Exercise 1",
   "id": "6768e56fde9a6809"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Crea un modelo de red neuronal con 6 capas densas y compara su exactitud (accuracy)",
   "id": "22fb75fb8ec0ce3e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-19T02:25:35.998236600Z",
     "start_time": "2025-12-19T02:24:33.110725800Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def classification_model_6layers():\n",
    "    # create model\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=(num_pixels,)))\n",
    "    model.add(Dense(num_pixels, activation='relu'))\n",
    "    model.add(Dense(100, activation='relu'))\n",
    "    model.add(Dense(100, activation='relu'))\n",
    "    model.add(Dense(100, activation='relu'))\n",
    "    model.add(Dense(100, activation='relu'))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "\n",
    "    # compile model\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# build the model\n",
    "model_6layers = classification_model_6layers()\n",
    "\n",
    "# fit the model\n",
    "model_6layers.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, verbose=2)\n",
    "\n",
    "# evaluate the model\n",
    "scores_6layers = model_6layers.evaluate(X_test, y_test, verbose=0)\n",
    "\n",
    "print('Accuracy_3_layers: {}% \\n Accuracy_6_layers: {}'.format(scores[1], scores_6layers[1]))"
   ],
   "id": "ee45512bdee94614",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1875/1875 - 8s - 4ms/step - accuracy: 0.8978 - loss: 0.4874 - val_accuracy: 0.9403 - val_loss: 0.2096\n",
      "Epoch 2/10\n",
      "1875/1875 - 6s - 3ms/step - accuracy: 0.9507 - loss: 0.1768 - val_accuracy: 0.9517 - val_loss: 0.1725\n",
      "Epoch 3/10\n",
      "1875/1875 - 6s - 3ms/step - accuracy: 0.9627 - loss: 0.1385 - val_accuracy: 0.9602 - val_loss: 0.1412\n",
      "Epoch 4/10\n",
      "1875/1875 - 6s - 3ms/step - accuracy: 0.9694 - loss: 0.1118 - val_accuracy: 0.9665 - val_loss: 0.1318\n",
      "Epoch 5/10\n",
      "1875/1875 - 6s - 3ms/step - accuracy: 0.9738 - loss: 0.0979 - val_accuracy: 0.9650 - val_loss: 0.1405\n",
      "Epoch 6/10\n",
      "1875/1875 - 6s - 3ms/step - accuracy: 0.9767 - loss: 0.0857 - val_accuracy: 0.9720 - val_loss: 0.1102\n",
      "Epoch 7/10\n",
      "1875/1875 - 6s - 3ms/step - accuracy: 0.9796 - loss: 0.0758 - val_accuracy: 0.9739 - val_loss: 0.1215\n",
      "Epoch 8/10\n",
      "1875/1875 - 6s - 3ms/step - accuracy: 0.9817 - loss: 0.0695 - val_accuracy: 0.9668 - val_loss: 0.1255\n",
      "Epoch 9/10\n",
      "1875/1875 - 6s - 3ms/step - accuracy: 0.9848 - loss: 0.0586 - val_accuracy: 0.9763 - val_loss: 0.0962\n",
      "Epoch 10/10\n",
      "1875/1875 - 6s - 3ms/step - accuracy: 0.9863 - loss: 0.0514 - val_accuracy: 0.9785 - val_loss: 0.1097\n",
      "Accuracy_3_layers: 0.9692999720573425% \n",
      " Accuracy_6_layers: 0.9785000085830688\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Practica Ejercicio 2",
   "id": "8cbe02ca43fb7d63"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Ahora, carga el modelo guardado anteriormente, entrena el modelo durante 10 épocas adicionales y verifica la exactitud (accuracy).",
   "id": "97af1242a693024b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "start_time": "2025-12-19T02:25:35.998236600Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#load the saved model\n",
    "pretrained_model = keras.saving.load_model('classification_model.keras')\n",
    "\n",
    "print(\"Pre-trained model loaded successufully\")\n",
    "\n",
    "# Further train the loaded model\n",
    "pretrained_model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, verbose=2)\n",
    "\n",
    "# evaluate the model\n",
    "scores_20_epochs = pretrained_model.evaluate(X_test, y_test, verbose=0)\n",
    "print('Accuracy_10_epochs: {}% \\n Accuracy_20_epochs: {}'.format(scores[1], scores_20_epochs[1]))"
   ],
   "id": "332a96d8dea7e0b2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-trained model loaded successufully\n",
      "Epoch 1/10\n",
      "1875/1875 - 6s - 3ms/step - accuracy: 0.9809 - loss: 0.0798 - val_accuracy: 0.9689 - val_loss: 0.1764\n",
      "Epoch 2/10\n",
      "1875/1875 - 6s - 3ms/step - accuracy: 0.9816 - loss: 0.0822 - val_accuracy: 0.9749 - val_loss: 0.1497\n",
      "Epoch 3/10\n",
      "1875/1875 - 5s - 3ms/step - accuracy: 0.9831 - loss: 0.0815 - val_accuracy: 0.9686 - val_loss: 0.1509\n",
      "Epoch 4/10\n"
     ]
    }
   ],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
